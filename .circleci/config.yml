version: 2
jobs:
  lint:
    docker:
      - image: golangci/golangci-lint:v1.45-alpine
    steps:
      - checkout
      - run: golangci-lint run

  # The kafka 0.10 tests are maintained as a separate configuration because
  # kafka only supported plain text SASL in this version.
  # NOTE: Bitnami does not have suport for kafka version 0.10.1.1. Hence we use 0.10.2.1
  kafka-010:
    working_directory: &working_directory /go/src/github.com/segmentio/kafka-go
    docker:
    - image: circleci/golang
    - image: bitnami/zookeeper:latest
      ports:
      - 2181:2181
      environment:
        ALLOW_ANONYMOUS_LOGIN: yes
    - image: bitnami/kafka:0.10.2.1
      ports:
      - 9092:9092
      - 9093:9093
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_DELETE_TOPIC_ENABLE: 'true'
        KAFKA_ADVERTISED_HOST_NAME: 'localhost'
        KAFKA_ADVERTISED_PORT: '9092'
        KAFKA_ZOOKEEPER_CONNECT: localhost:2181
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
        KAFKA_MESSAGE_MAX_BYTES: '200000000'
        KAFKA_LISTENERS: 'PLAINTEXT://:9092,SASL_PLAINTEXT://:9093'
        KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://localhost:9092,SASL_PLAINTEXT://localhost:9093'
        KAFKA_SASL_ENABLED_MECHANISMS: 'PLAIN,SCRAM-SHA-256,SCRAM-SHA-512'
        KAFKA_AUTHORIZER_CLASS_NAME: 'kafka.security.auth.SimpleAclAuthorizer'
        KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: 'true'
        KAFKA_OPTS: "-Djava.security.auth.login.config=/opt/bitnami/kafka/config/kafka_server_jaas.conf"
        ALLOW_PLAINTEXT_LISTENER: yes
      entrypoint:
        - "/bin/bash"
        - "-c"
        - echo -e 'KafkaServer {\norg.apache.kafka.common.security.scram.ScramLoginModule required\n username="adminscram"\n password="admin-secret";\n org.apache.kafka.common.security.plain.PlainLoginModule required\n username="adminplain"\n password="admin-secret"\n user_adminplain="admin-secret";\n  };' > /opt/bitnami/kafka/config/kafka_server_jaas.conf; /opt/bitnami/kafka/bin/kafka-configs.sh --zookeeper localhost:2181 --alter --add-config 'SCRAM-SHA-256=[password=admin-secret-256],SCRAM-SHA-512=[password=admin-secret-512]' --entity-type users --entity-name adminscram; exec /app-entrypoint.sh /start-kafka.sh

    steps: &steps
    - checkout
    - restore_cache:
        key: kafka-go-mod-{{ checksum "go.sum" }}-1
    - run:
        name: Download dependencies
        command: go mod download
    - save_cache:
        key: kafka-go-mod-{{ checksum "go.sum" }}-1
        paths:
        - /go/pkg/mod
    - run:
        name: Wait for kafka
        command: ./scripts/wait-for-kafka.sh
    - run:
        name: Test kafka-go
        command: go test -race -cover ./...
    - run:
        name: Test kafka-go unsafe
        command: go test -tags=unsafe -race -cover ./...
    - run:
        name: Test kafka-go/sasl/aws_msk_iam
        working_directory: ./sasl/aws_msk_iam
        command: go test -race -cover ./...

  # NOTE: Bitnami does not have suport for kafka version 2.7.1. Hence we use 2.7.0
  kafka-270:
    working_directory: *working_directory
    environment:
      KAFKA_VERSION: "2.7.0"

      # Need to skip nettest to avoid these kinds of errors:
      #  --- FAIL: TestConn/nettest (17.56s)
      #    --- FAIL: TestConn/nettest/PingPong (7.40s)
      #      conntest.go:112: unexpected Read error: [7] Request Timed Out: the request exceeded the user-specified time limit in the request
      #      conntest.go:118: mismatching value: got 77, want 78
      #      conntest.go:118: mismatching value: got 78, want 79
      # ...
      #
      # TODO: Figure out why these are happening and fix them (they don't appear to be new).
      KAFKA_SKIP_NETTEST: "1"
    docker:
    - image: circleci/golang
    - image: bitnami/zookeeper:latest
      ports:
      - 2181:2181
      environment:
        ALLOW_ANONYMOUS_LOGIN: yes
    - image: bitnami/kafka:2.7.0
      ports:
      - 9092:9092
      - 9093:9093
      environment: &environment
        KAFKA_CFG_BROKER_ID: 1
        KAFKA_CFG_DELETE_TOPIC_ENABLE: 'true'
        KAFKA_CFG_ADVERTISED_HOST_NAME: 'localhost'
        KAFKA_CFG_ADVERTISED_PORT: '9092'
        KAFKA_CFG_ZOOKEEPER_CONNECT: localhost:2181
        KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'true'
        KAFKA_CFG_MESSAGE_MAX_BYTES: '200000000'
        KAFKA_CFG_LISTENERS: 'PLAINTEXT://:9092,SASL_PLAINTEXT://:9093'
        KAFKA_CFG_ADVERTISED_LISTENERS: 'PLAINTEXT://localhost:9092,SASL_PLAINTEXT://localhost:9093'
        KAFKA_CFG_SASL_ENABLED_MECHANISMS: 'PLAIN,SCRAM-SHA-256,SCRAM-SHA-512'
        KAFKA_CFG_AUTHORIZER_CLASS_NAME: 'kafka.security.auth.SimpleAclAuthorizer'
        KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND: 'true'
        KAFKA_OPTS: "-Djava.security.auth.login.config=/opt/bitnami/kafka/config/kafka_jaas.conf"
        ALLOW_PLAINTEXT_LISTENER: yes
      entrypoint: &entrypoint
        - "/bin/bash"
        - "-c"
        - echo -e 'KafkaServer {\norg.apache.kafka.common.security.scram.ScramLoginModule required\n username="adminscram"\n password="admin-secret";\n org.apache.kafka.common.security.plain.PlainLoginModule required\n username="adminplain"\n password="admin-secret"\n user_adminplain="admin-secret";\n  };' > /opt/bitnami/kafka/config/kafka_jaas.conf; /opt/bitnami/kafka/bin/kafka-configs.sh --zookeeper localhost:2181 --alter --add-config "SCRAM-SHA-256=[password=admin-secret-256],SCRAM-SHA-512=[password=admin-secret-512]" --entity-type users --entity-name adminscram; exec /entrypoint.sh /run.sh
    steps: *steps

  kafka-281:
    working_directory: *working_directory
    environment:
      KAFKA_VERSION: "2.8.1"

      # Need to skip nettest to avoid these kinds of errors:
      #  --- FAIL: TestConn/nettest (17.56s)
      #    --- FAIL: TestConn/nettest/PingPong (7.40s)
      #      conntest.go:112: unexpected Read error: [7] Request Timed Out: the request exceeded the user-specified time limit in the request
      #      conntest.go:118: mismatching value: got 77, want 78
      #      conntest.go:118: mismatching value: got 78, want 79
      # ...
      #
      # TODO: Figure out why these are happening and fix them (they don't appear to be new).
      KAFKA_SKIP_NETTEST: "1"
    docker:
    - image: circleci/golang
    - image: bitnami/zookeeper:latest
      ports:
      - 2181:2181
      environment:
        ALLOW_ANONYMOUS_LOGIN: yes
    - image: bitnami/kafka:2.8.1
      ports:
      - 9092:9092
      - 9093:9093
      environment: *environment
      entrypoint: *entrypoint
    steps: *steps

  kafka-370:
    working_directory: *working_directory
    environment:
      KAFKA_VERSION: "3.7.0"

      # Need to skip nettest to avoid these kinds of errors:
      #  --- FAIL: TestConn/nettest (17.56s)
      #    --- FAIL: TestConn/nettest/PingPong (7.40s)
      #      conntest.go:112: unexpected Read error: [7] Request Timed Out: the request exceeded the user-specified time limit in the request
      #      conntest.go:118: mismatching value: got 77, want 78
      #      conntest.go:118: mismatching value: got 78, want 79
      # ...
      #
      # TODO: Figure out why these are happening and fix them (they don't appear to be new).
      KAFKA_SKIP_NETTEST: "1"
    docker:
    - image: circleci/golang
    - image: bitnami/zookeeper:latest
      ports:
      - 2181:2181
      environment:
        ALLOW_ANONYMOUS_LOGIN: yes
    - image: bitnami/kafka:3.7.0
      ports:
        - 9092:9092
        - 9093:9093
      environment:
        <<: *environment
        KAFKA_CFG_AUTHORIZER_CLASS_NAME: 'kafka.security.authorizer.AclAuthorizer'
      entrypoint: *entrypoint
    steps: *steps

  # NOTE: this fails quite often due to Java heap errors from Kafka.
  # Once we switch to Github actions and can use larger instances, we can
  # set the heap size and enable these
  # kafka-400:
  #   working_directory: *working_directory
  #   environment:
  #     KAFKA_VERSION: "4.0.0"

  #     # Need to skip nettest to avoid these kinds of errors:
  #     #  --- FAIL: TestConn/nettest (17.56s)
  #     #    --- FAIL: TestConn/nettest/PingPong (7.40s)
  #     #      conntest.go:112: unexpected Read error: [7] Request Timed Out: the request exceeded the user-specified time limit in the request
  #     #      conntest.go:118: mismatching value: got 77, want 78
  #     #      conntest.go:118: mismatching value: got 78, want 79
  #     # ...
  #     #
  #     # TODO: Figure out why these are happening and fix them (they don't appear to be new).
  #     KAFKA_SKIP_NETTEST: "1"
  #   docker:
  #   - image: circleci/golang
  #   - image: bitnami/kafka:4.0.0
  #     ports:
  #       - 9092:9092
  #       - 9093:9093
  #     environment:
  #       KAFKA_CFG_NODE_ID: 1
  #       KAFKA_CFG_BROKER_ID: 1
  #       KAFKA_CFG_PROCESS_ROLES: broker,controller
  #       KAFKA_CFG_ADVERTISED_HOST_NAME: 'localhost'
  #       KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
  #       KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAIN:PLAINTEXT,SASL:SASL_PLAINTEXT
  #       KAFKA_CFG_LISTENERS: CONTROLLER://:9094,PLAIN://:9092,SASL://:9093
  #       KAFKA_CFG_ADVERTISED_LISTENERS: PLAIN://localhost:9092,SASL://localhost:9093
  #       KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAIN
  #       KAFKA_CFG_SASL_ENABLED_MECHANISMS: 'PLAIN,SCRAM-SHA-256,SCRAM-SHA-512'
  #       KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@localhost:9094
  #       ALLOW_PLAINTEXT_LISTENER: yes
  #       KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND: 'true'
  #       KAFKA_OPTS: "-Djava.security.auth.login.config=/opt/bitnami/kafka/config/kafka_jaas.conf"
  #       KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'true'
  #       KAFKA_CFG_DELETE_TOPIC_ENABLE: 'true'
  #       KAFKA_CFG_MESSAGE_MAX_BYTES: '200000000'
  #       KAFKA_CFG_AUTHORIZER_CLASS_NAME: 'org.apache.kafka.metadata.authorizer.StandardAuthorizer'
  #       KAFKA_CFG_SUPER_USERS: User:adminscram256;User:adminscram512;User:adminplain
  #       KAFKA_CLIENT_USERS: adminscram256,adminscram512,adminplain
  #       KAFKA_CLIENT_PASSWORDS: admin-secret-256,admin-secret-512,admin-secret
  #       KAFKA_CLIENT_SASL_MECHANISMS: SCRAM-SHA-256,SCRAM-SHA-512,PLAIN
  #       KAFKA_INTER_BROKER_USER: adminscram512
  #       KAFKA_INTER_BROKER_PASSWORD: admin-secret-512
  #       KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512
  #   steps: *steps

workflows:
  version: 2
  run:
    jobs:
    - lint
    - kafka-010
    - kafka-270
    - kafka-281
    - kafka-370 
    #- kafka-400
